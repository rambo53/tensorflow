{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fba089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "ici je n'ai pas chargé de data, mais de base il s'agit de dessin récupérer en ligne sur quick draw\n",
    "puis stocké dans des fichiers et ensuite assemblé en un seul de 10 050 valeurs\n",
    "'''\n",
    "images, images_valid, targets, targets_valid = train_test_split(images, targets, test_size=0.33)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_images = scaler.fit_transform(images.reshape(-1, 28*28))\n",
    "scaled_images_valid = scaler.transform(images_valid.reshape(-1, 28*28))\n",
    "print(\"Mean and std of scaled images\", scaled_images.mean(), scaled_images.std())\n",
    "\n",
    "scaled_images = scaled_images.reshape(-1, 28, 28, 1)\n",
    "scaled_images_valid = scaled_images_valid.reshape(-1, 28, 28, 1)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((scaled_images, targets))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((scaled_images_valid, targets_valid))\n",
    "\n",
    "# mon model de convolution personnalisé\n",
    "class ConvModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        # Convolutions première conv = 32 filtres de 4 par 4\n",
    "        # et ma deuxième appliquera une conv sur le résultat de la première, et ainsi de suite\n",
    "        # qui pour rappel sera mon image en plus petit\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 4, activation='relu', name=\"conv1\")\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation='relu', name=\"conv2\")\n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, 3, activation='relu', name=\"conv3\")\n",
    "        # Flatten the convolution\n",
    "        self.flatten = tf.keras.layers.Flatten(name=\"flatten\")       \n",
    "        # Dense layers\n",
    "        self.d1 = tf.keras.layers.Dense(128, activation='relu', name=\"d1\")\n",
    "        self.out = tf.keras.layers.Dense(10, activation='softmax', name=\"output\")\n",
    "\n",
    "    def call(self, image):\n",
    "        conv1 = self.conv1(image)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        flatten = self.flatten(conv3)\n",
    "        d1 = self.d1(flatten)\n",
    "        output = self.out(d1)\n",
    "        return output\n",
    "\n",
    "model = ConvModel()\n",
    "model.predict(scaled_images[0:1])\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "# Loss\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "# Accuracy\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def valid_step(image, targets):\n",
    "    predictions = model(image)\n",
    "    t_loss = loss_object(targets, predictions)\n",
    "    # Set the metrics for the test\n",
    "    valid_loss(t_loss)\n",
    "    valid_accuracy(targets, predictions)\n",
    "    \n",
    "\n",
    "epoch = 10\n",
    "batch_size = 32\n",
    "b = 0\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    # Training set\n",
    "    for images_batch, targets_batch in train_dataset.batch(batch_size):\n",
    "        train_step(images_batch, targets_batch)\n",
    "        template = '\\r Batch {}/{}, Loss: {}, Accuracy: {}'\n",
    "        print(template.format(\n",
    "            b, len(targets), train_loss.result(), \n",
    "            train_accuracy.result()*100\n",
    "        ), end=\"\")\n",
    "        b += batch_size\n",
    "    # Validation set\n",
    "    for images_batch, targets_batch in valid_dataset.batch(batch_size):\n",
    "        valid_step(images_batch, targets_batch)\n",
    "\n",
    "    template = '\\nEpoch {}, Valid Loss: {}, Valid Accuracy: {}'\n",
    "    print(template.format(\n",
    "        epoch+1,\n",
    "        valid_loss.result(), \n",
    "        valid_accuracy.result()*100)\n",
    "    )\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    train_loss.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
